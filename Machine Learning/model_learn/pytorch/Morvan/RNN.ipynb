{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ea9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0dbfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = False   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b082b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5991f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[1].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0985e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d65df23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e551ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.test_labels.numpy()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42296add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5176b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec2e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ae494ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3044 | test accuracy: 0.11\n",
      "Epoch:  0 | train loss: 1.1886 | test accuracy: 0.52\n",
      "Epoch:  0 | train loss: 0.9248 | test accuracy: 0.66\n",
      "Epoch:  0 | train loss: 0.5832 | test accuracy: 0.73\n",
      "Epoch:  0 | train loss: 0.4468 | test accuracy: 0.85\n",
      "Epoch:  0 | train loss: 0.2884 | test accuracy: 0.87\n",
      "Epoch:  0 | train loss: 0.3298 | test accuracy: 0.89\n",
      "Epoch:  0 | train loss: 0.2141 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.2430 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1817 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1742 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.0519 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2517 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1674 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.3218 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.0446 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.2304 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1252 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1680 | test accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = x.view(-1, 28, 28)             # reshape x to (batch, time_step, input_size)\n",
    "        b_y = y                               # batch y\n",
    "\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item(), '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c157e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "# import numpy as np\n",
    "# np.argmax(test_output, 1)\n",
    "pred_y = torch.max(test_output, 1)[1].numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f04a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
